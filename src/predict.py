import cv2
import numpy as np
import tensorflow as tf
import json

# Ng∆∞·ª°ng c·∫•u h√¨nh
HSV_AREA_THRESHOLD = 0.15
AI_CONF_THRESHOLD = 0.75
SAFE_FALLBACK_THRESHOLD = 0.95

# Load class names t·ª´ JSON (ƒë·ªìng b·ªô v·ªõi train.py)
CLASS_NAMES = ['apple', 'banana', 'grapes', 'guava', 'orange']
try:
    with open('models/class_names.json', 'r', encoding='utf-8') as f:
        CLASS_NAMES = json.load(f)
    print(f"‚úÖ Loaded class names: {CLASS_NAMES}")
except FileNotFoundError:
    print(f"‚ö†Ô∏è class_names.json not found, using default: {CLASS_NAMES}")

def hsv_gate_check(frame):
    """
    Ki·ªÉm tra xem frame c√≥ ch·ª©a tr√°i c√¢y kh√¥ng d·ª±a tr√™n HSV color space.
    
    Returns:
        is_fruit (bool): True n·∫øu ph√°t hi·ªán m√†u s·∫Øc tr√°i c√¢y
        ratio (float): T·ª∑ l·ªá pixel m√†u tr√°i c√¢y
    """
    if frame is None or frame.size == 0:
        return False, 0.0
    
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    # Nh√≥m 1: S√°ng (Cam, Chu·ªëi, T√°o xanh)
    mask1 = cv2.inRange(hsv, np.array([10, 100, 60]), np.array([90, 255, 255]))
    
    # Nh√≥m 2: T·ªëi (Nho ƒëen, T√°o ƒë·ªè)
    mask2 = cv2.inRange(hsv, np.array([120, 100, 30]), np.array([180, 255, 255]))
    
    # FIXED: Th√™m d·∫£i ƒë·ªè cho t√°o ƒë·ªè, d√¢u (Hue wrap around 0-180)
    mask_red1 = cv2.inRange(hsv, np.array([0, 100, 60]), np.array([10, 255, 255]))
    mask_red2 = cv2.inRange(hsv, np.array([170, 100, 60]), np.array([180, 255, 255]))
    
    # Combine t·∫•t c·∫£ masks
    mask = cv2.bitwise_or(mask1, mask2)
    mask = cv2.bitwise_or(mask, cv2.bitwise_or(mask_red1, mask_red2))
    
    # Kh·ª≠ nhi·ªÖu nh·∫π (optional - gi√∫p ·ªïn ƒë·ªãnh h∆°n)
    kernel = np.ones((3, 3), np.uint8)
    mask = cv2.erode(mask, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=2)
    
    ratio = np.count_nonzero(mask) / (frame.shape[0] * frame.shape[1])
    return ratio > HSV_AREA_THRESHOLD, ratio

def preprocess_image(frame):
    """
    Resize v√† chu·∫©n b·ªã ·∫£nh cho model.
    Kh√¥ng c·∫ßn normalize v√¨ model ƒë√£ nh√∫ng preprocessing.
    """
    img = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)
    img = np.expand_dims(img.astype(np.float32), axis=0)
    return img

def predict_fruit(model, frame):
    """
    Predict tr√°i c√¢y v·ªõi Double Gate: HSV + Softmax confidence.
    
    Args:
        model: Trained Keras model
        frame: BGR image from OpenCV
    
    Returns:
        label (str): T√™n tr√°i c√¢y ho·∫∑c "Not a fruit"/"Unknown Object"
        score (float): Confidence score [0-1]
    """
    is_fruit, ratio = hsv_gate_check(frame)
    img = preprocess_image(frame)
    
    # OPTIMIZED: D√πng model() thay v√¨ predict() ‚Üí nhanh h∆°n 3-5x
    preds = model(img, training=False).numpy()
    score = float(np.max(preds))
    label = CLASS_NAMES[int(np.argmax(preds))]
    
    # Double Gate Logic
    if score > SAFE_FALLBACK_THRESHOLD:
        # Confidence c·ª±c cao ‚Üí tin AI 100%
        return label, score
    
    if not is_fruit:
        # HSV kh√¥ng detect m√†u tr√°i c√¢y ‚Üí reject
        return "Not a fruit", score
    
    if score < AI_CONF_THRESHOLD:
        # Confidence th·∫•p ‚Üí unknown
        return "Unknown Object", score
    
    return label, score

# ===== DEMO: Real-time webcam inference =====
if __name__ == "__main__":
    try:
        # Load model
        print("Loading model...")
        model = tf.keras.models.load_model('models/best_model.h5')
        print("‚úÖ Model loaded successfully")
        
        # OPTIONAL: Compile v·ªõi XLA ƒë·ªÉ nhanh h∆°n
        # model.compile(jit_compile=True)
        
        # Open webcam
        cap = cv2.VideoCapture(0)
        print("üì∑ Webcam opened. Press 'q' to quit.")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Failed to grab frame")
                break
            
            # Predict
            label, score = predict_fruit(model, frame)
            
            # Display result
            color = (0, 255, 0) if label not in ["Not a fruit", "Unknown Object"] else (0, 0, 255)
            cv2.putText(frame, f"{label}: {score:.2f}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            
            cv2.imshow("Fruit Detection", frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
    except FileNotFoundError:
        print("‚ùå Model file not found. Please train the model first by running train.py")
    except Exception as e:
        print(f"‚ùå Error: {e}")